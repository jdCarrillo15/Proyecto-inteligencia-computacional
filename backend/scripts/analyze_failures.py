#!/usr/bin/env python3
"""
An√°lisis de Problemas del Modelo - Paso 5
==========================================
Analiza fallos del modelo cuando no pasa validaci√≥n.

Ejecutado autom√°ticamente cuando el modelo es RECHAZADO o CONDICIONAL.

Funcionalidades:
‚úÖ Identificar clases con bajo rendimiento
‚úÖ Analizar confusion matrix (confusiones m√°s frecuentes)
‚úÖ Detectar patrones de error
‚úÖ Generar reporte con recomendaciones espec√≠ficas:
   - Aumentar data augmentation
   - Ajustar class weights
   - Cambiar arquitectura
   - Aumentar epochs o learning rate

Uso:
    python backend/scripts/analyze_failures.py
    python backend/scripts/analyze_failures.py --results metrics/evaluation_results.json
"""

import sys
import json
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any
from collections import defaultdict

# A√±adir backend al path
backend_dir = Path(__file__).parent.parent
if str(backend_dir) not in sys.path:
    sys.path.insert(0, str(backend_dir))

from config import (
    PERFORMANCE_THRESHOLDS,
    CRITICAL_DISEASE_CLASSES,
    CRITICAL_DISEASE_MIN_RECALL,
    CLASSES
)

# Colores para terminal
GREEN = '\033[92m'
YELLOW = '\033[93m'
RED = '\033[91m'
BLUE = '\033[94m'
MAGENTA = '\033[95m'
CYAN = '\033[96m'
BOLD = '\033[1m'
RESET = '\033[0m'


class FailureAnalyzer:
    """Analiza problemas del modelo y genera recomendaciones."""
    
    def __init__(self, results_path: str = None, validation_path: str = None):
        """
        Inicializa el analizador.
        
        Args:
            results_path: Ruta al JSON con resultados de evaluaci√≥n
            validation_path: Ruta al JSON con reporte de validaci√≥n
        """
        if results_path is None:
            results_path = backend_dir.parent / 'metrics' / 'evaluation_results.json'
        if validation_path is None:
            validation_path = backend_dir.parent / 'metrics' / 'validation_report.json'
        
        self.results_path = Path(results_path)
        self.validation_path = Path(validation_path)
        self.results = None
        self.validation = None
        self.analysis = {
            'timestamp': datetime.now().isoformat(),
            'problematic_classes': [],
            'confusion_patterns': [],
            'error_analysis': {},
            'recommendations': [],
            'priority_actions': []
        }
    
    def load_data(self) -> bool:
        """Carga datos de evaluaci√≥n y validaci√≥n."""
        # Cargar resultados de evaluaci√≥n
        if not self.results_path.exists():
            print(f"{RED}‚ùå No se encontr√≥ {self.results_path}{RESET}")
            print(f"{YELLOW}‚ö†Ô∏è  Ejecuta primero: python backend/scripts/evaluate_model.py{RESET}")
            return False
        
        try:
            with open(self.results_path, 'r', encoding='utf-8') as f:
                self.results = json.load(f)
        except Exception as e:
            print(f"{RED}‚ùå Error al cargar resultados: {e}{RESET}")
            return False
        
        # Cargar reporte de validaci√≥n (opcional)
        if self.validation_path.exists():
            try:
                with open(self.validation_path, 'r', encoding='utf-8') as f:
                    self.validation = json.load(f)
            except Exception as e:
                print(f"{YELLOW}‚ö†Ô∏è  No se pudo cargar reporte de validaci√≥n: {e}{RESET}")
        
        return True
    
    def identify_problematic_classes(self) -> List[Dict[str, Any]]:
        """
        Identifica clases con bajo rendimiento.
        
        Returns:
            Lista de clases problem√°ticas con sus m√©tricas
        """
        print(f"\n{BOLD}{'='*70}{RESET}")
        print(f"{BOLD}üîç IDENTIFICACI√ìN DE CLASES PROBLEM√ÅTICAS{RESET}")
        print(f"{BOLD}{'='*70}{RESET}\n")
        
        per_class = self.results.get('per_class_metrics', {})
        problematic = []
        
        min_recall = PERFORMANCE_THRESHOLDS['min_recall_per_class']
        min_precision = PERFORMANCE_THRESHOLDS['min_precision_per_class']
        min_f1 = PERFORMANCE_THRESHOLDS['min_f1_per_class']
        
        target_recall = PERFORMANCE_THRESHOLDS['target_recall_per_class']
        target_precision = PERFORMANCE_THRESHOLDS['target_precision_per_class']
        target_f1 = PERFORMANCE_THRESHOLDS['target_f1_per_class']
        
        for class_name, metrics in per_class.items():
            recall = metrics.get('recall', 0.0)
            precision = metrics.get('precision', 0.0)
            f1 = metrics.get('f1_score', 0.0)
            support = metrics.get('support', 0)
            
            issues = []
            severity = 'OK'
            
            # Detectar problemas
            if recall < min_recall:
                issues.append(f"Recall cr√≠tico: {recall:.4f} < {min_recall:.2f}")
                severity = 'CRITICAL'
            elif recall < target_recall:
                issues.append(f"Recall bajo: {recall:.4f} < {target_recall:.2f}")
                if severity == 'OK':
                    severity = 'WARNING'
            
            if precision < min_precision:
                issues.append(f"Precision cr√≠tica: {precision:.4f} < {min_precision:.2f}")
                severity = 'CRITICAL'
            elif precision < target_precision:
                issues.append(f"Precision baja: {precision:.4f} < {target_precision:.2f}")
                if severity == 'OK':
                    severity = 'WARNING'
            
            if f1 < min_f1:
                issues.append(f"F1 cr√≠tico: {f1:.4f} < {min_f1:.2f}")
                severity = 'CRITICAL'
            elif f1 < target_f1:
                issues.append(f"F1 bajo: {f1:.4f} < {target_f1:.2f}")
                if severity == 'OK':
                    severity = 'WARNING'
            
            # Clases cr√≠ticas requieren mayor recall
            if class_name in CRITICAL_DISEASE_CLASSES:
                if recall < CRITICAL_DISEASE_MIN_RECALL:
                    issues.append(f"Recall CR√çTICO (enfermedad cr√≠tica): {recall:.4f} < {CRITICAL_DISEASE_MIN_RECALL:.2f}")
                    severity = 'CRITICAL'
            
            if issues:
                problematic.append({
                    'class_name': class_name,
                    'severity': severity,
                    'recall': recall,
                    'precision': precision,
                    'f1_score': f1,
                    'support': support,
                    'issues': issues,
                    'is_critical_disease': class_name in CRITICAL_DISEASE_CLASSES
                })
        
        # Ordenar por severidad y luego por F1
        severity_order = {'CRITICAL': 0, 'WARNING': 1, 'OK': 2}
        problematic.sort(key=lambda x: (severity_order[x['severity']], x['f1_score']))
        
        # Mostrar resultados
        if not problematic:
            print(f"{GREEN}‚úÖ No se detectaron clases problem√°ticas{RESET}")
            print(f"{GREEN}   Todas las clases cumplen con los umbrales m√≠nimos{RESET}\n")
        else:
            print(f"{RED}‚ö†Ô∏è  Se detectaron {len(problematic)} clases problem√°ticas:{RESET}\n")
            
            for item in problematic:
                if item['severity'] == 'CRITICAL':
                    icon = f"{RED}üî¥{RESET}"
                    severity_label = f"{RED}CR√çTICO{RESET}"
                else:
                    icon = f"{YELLOW}‚ö†Ô∏è{RESET}"
                    severity_label = f"{YELLOW}ADVERTENCIA{RESET}"
                
                class_display = item['class_name'].replace('_', ' ')
                if item['is_critical_disease']:
                    class_display = f"{class_display} {MAGENTA}[ENFERMEDAD CR√çTICA]{RESET}"
                
                print(f"{icon} {BOLD}{class_display}{RESET} - {severity_label}")
                print(f"   Recall: {item['recall']:.4f} | Precision: {item['precision']:.4f} | F1: {item['f1_score']:.4f} | Support: {item['support']}")
                
                for issue in item['issues']:
                    print(f"   ‚Ä¢ {issue}")
                print()
        
        self.analysis['problematic_classes'] = problematic
        return problematic
    
    def analyze_confusion_matrix(self) -> List[Dict[str, Any]]:
        """
        Analiza confusion matrix para detectar confusiones frecuentes.
        
        Returns:
            Lista de patrones de confusi√≥n detectados
        """
        print(f"{BOLD}{'='*70}{RESET}")
        print(f"{BOLD}üîÄ AN√ÅLISIS DE CONFUSION MATRIX{RESET}")
        print(f"{BOLD}{'='*70}{RESET}\n")
        
        cm = self.results.get('confusion_matrix', [])
        class_names = self.results.get('class_names', CLASSES)
        
        if not cm:
            print(f"{RED}‚ùå No se encontr√≥ confusion matrix en los resultados{RESET}\n")
            return []
        
        cm = np.array(cm)
        n_classes = len(class_names)
        
        # Encontrar confusiones significativas (excluyendo diagonal)
        confusions = []
        
        for i in range(n_classes):
            total_true = cm[i, :].sum()
            if total_true == 0:
                continue
            
            for j in range(n_classes):
                if i == j:  # Saltar diagonal (predicciones correctas)
                    continue
                
                count = cm[i, j]
                if count == 0:
                    continue
                
                # Porcentaje de veces que la clase i se confundi√≥ con j
                confusion_rate = count / total_true
                
                # Solo considerar confusiones > 5%
                if confusion_rate > 0.05:
                    confusions.append({
                        'true_class': class_names[i],
                        'predicted_class': class_names[j],
                        'count': int(count),
                        'total_true': int(total_true),
                        'confusion_rate': confusion_rate
                    })
        
        # Ordenar por tasa de confusi√≥n
        confusions.sort(key=lambda x: x['confusion_rate'], reverse=True)
        
        # Mostrar top confusiones
        if not confusions:
            print(f"{GREEN}‚úÖ No se detectaron confusiones significativas (>5%){RESET}\n")
        else:
            print(f"{YELLOW}‚ö†Ô∏è  Top confusiones detectadas:{RESET}\n")
            
            for i, conf in enumerate(confusions[:10], 1):  # Top 10
                true_cls = conf['true_class'].replace('_', ' ')
                pred_cls = conf['predicted_class'].replace('_', ' ')
                rate = conf['confusion_rate'] * 100
                count = conf['count']
                total = conf['total_true']
                
                print(f"{i:2d}. {BOLD}{true_cls}{RESET}")
                print(f"    ‚Üí confundido con {CYAN}{pred_cls}{RESET}")
                print(f"    üìä {count}/{total} veces ({rate:.1f}%)\n")
        
        self.analysis['confusion_patterns'] = confusions
        return confusions
    
    def detect_error_patterns(self) -> Dict[str, Any]:
        """
        Detecta patrones de error en el modelo.
        
        Returns:
            Diccionario con an√°lisis de patrones
        """
        print(f"{BOLD}{'='*70}{RESET}")
        print(f"{BOLD}üîé DETECCI√ìN DE PATRONES DE ERROR{RESET}")
        print(f"{BOLD}{'='*70}{RESET}\n")
        
        patterns = {
            'low_recall_classes': [],
            'low_precision_classes': [],
            'inter_crop_confusion': defaultdict(list),
            'healthy_vs_diseased_errors': [],
            'similar_symptom_confusion': []
        }
        
        per_class = self.results.get('per_class_metrics', {})
        
        # Clases con bajo recall (falsos negativos altos)
        low_recall = [(name, m['recall']) for name, m in per_class.items() 
                      if m['recall'] < PERFORMANCE_THRESHOLDS['target_recall_per_class']]
        low_recall.sort(key=lambda x: x[1])
        
        if low_recall:
            print(f"{YELLOW}üìâ Clases con bajo Recall (alto False Negative):{RESET}")
            for name, recall in low_recall[:5]:
                print(f"   ‚Ä¢ {name.replace('_', ' ')}: {recall:.4f}")
            patterns['low_recall_classes'] = low_recall
            print()
        
        # Clases con baja precision (falsos positivos altos)
        low_precision = [(name, m['precision']) for name, m in per_class.items() 
                        if m['precision'] < PERFORMANCE_THRESHOLDS['target_precision_per_class']]
        low_precision.sort(key=lambda x: x[1])
        
        if low_precision:
            print(f"{YELLOW}üìà Clases con baja Precision (alto False Positive):{RESET}")
            for name, precision in low_precision[:5]:
                print(f"   ‚Ä¢ {name.replace('_', ' ')}: {precision:.4f}")
            patterns['low_precision_classes'] = low_precision
            print()
        
        # Detectar confusi√≥n entre cultivos (Apple, Corn, Potato, Tomato)
        confusions = self.analysis.get('confusion_patterns', [])
        for conf in confusions:
            true_crop = conf['true_class'].split('___')[0]
            pred_crop = conf['predicted_class'].split('___')[0]
            
            if true_crop != pred_crop:
                patterns['inter_crop_confusion'][true_crop].append({
                    'confused_with': pred_crop,
                    'rate': conf['confusion_rate']
                })
        
        if patterns['inter_crop_confusion']:
            print(f"{RED}üåæ Confusi√≥n entre diferentes cultivos:{RESET}")
            for crop, confusions_list in patterns['inter_crop_confusion'].items():
                print(f"   ‚Ä¢ {crop}:")
                for c in confusions_list[:3]:
                    print(f"     ‚Üí {c['confused_with']}: {c['rate']*100:.1f}%")
            print()
        
        # Detectar confusi√≥n healthy vs diseased
        for conf in confusions:
            true_healthy = 'healthy' in conf['true_class'].lower()
            pred_healthy = 'healthy' in conf['predicted_class'].lower()
            
            if true_healthy != pred_healthy:
                patterns['healthy_vs_diseased_errors'].append(conf)
        
        if patterns['healthy_vs_diseased_errors']:
            print(f"{MAGENTA}üî¨ Confusi√≥n Healthy vs Diseased:{RESET}")
            for conf in patterns['healthy_vs_diseased_errors'][:5]:
                true_cls = conf['true_class'].replace('_', ' ')
                pred_cls = conf['predicted_class'].replace('_', ' ')
                print(f"   ‚Ä¢ {true_cls} ‚Üí {pred_cls}: {conf['confusion_rate']*100:.1f}%")
            print()
        
        self.analysis['error_analysis'] = patterns
        return patterns
    
    def generate_recommendations(self, problematic_classes: List[Dict], 
                                 confusions: List[Dict],
                                 error_patterns: Dict) -> List[str]:
        """
        Genera recomendaciones espec√≠ficas basadas en el an√°lisis.
        
        Args:
            problematic_classes: Clases con bajo rendimiento
            confusions: Patrones de confusi√≥n
            error_patterns: Patrones de error detectados
        
        Returns:
            Lista de recomendaciones priorizadas
        """
        print(f"{BOLD}{'='*70}{RESET}")
        print(f"{BOLD}üí° RECOMENDACIONES ESPEC√çFICAS{RESET}")
        print(f"{BOLD}{'='*70}{RESET}\n")
        
        recommendations = []
        priority_actions = []
        
        # Analizar problemas globales
        global_metrics = self.results.get('global_metrics', {})
        macro_f1 = global_metrics.get('macro_f1', 0.0)
        accuracy = global_metrics.get('accuracy', 0.0)
        
        # 1. Problemas de Data Augmentation
        if len(problematic_classes) > len(CLASSES) * 0.3:  # >30% clases problem√°ticas
            rec = {
                'category': 'Data Augmentation',
                'priority': 'HIGH',
                'issue': f'{len(problematic_classes)} clases ({len(problematic_classes)/len(CLASSES)*100:.0f}%) con bajo rendimiento',
                'actions': [
                    'Aumentar intensidad de augmentation en config.py:',
                    '  - rotation_range: 20 ‚Üí 30',
                    '  - zoom_range: 0.2 ‚Üí 0.3',
                    '  - Agregar brightness_range: [0.8, 1.2]',
                    '  - Agregar vertical_flip: True',
                    'Aplicar augmentation m√°s agresivo en clases problem√°ticas',
                    'Considerar t√©cnicas avanzadas: mixup, cutout, random erasing'
                ]
            }
            recommendations.append(rec)
            priority_actions.append("üé® Aumentar Data Augmentation")
        
        # 2. Problemas de Class Weights
        if problematic_classes:
            low_support_classes = [c for c in problematic_classes if c['support'] < 100]
            if low_support_classes:
                rec = {
                    'category': 'Class Weights',
                    'priority': 'HIGH',
                    'issue': f'{len(low_support_classes)} clases con pocas muestras (<100)',
                    'actions': [
                        'Ajustar class weights en train.py para clases con bajo soporte:',
                        '  - Aumentar peso para: ' + ', '.join([c['class_name'] for c in low_support_classes[:3]]),
                        'Considerar oversampling para clases minoritarias',
                        'Verificar TARGET_SAMPLES_PER_CLASS en config.py',
                        'Aumentar TARGET_BALANCE_RATIO si hay desbalanceo severo'
                    ]
                }
                recommendations.append(rec)
                priority_actions.append("‚öñÔ∏è  Ajustar Class Weights")
        
        # 3. Problemas de Learning Rate
        if macro_f1 < PERFORMANCE_THRESHOLDS['min_macro_f1']:
            rec = {
                'category': 'Learning Rate',
                'priority': 'HIGH',
                'issue': f'Macro F1 bajo: {macro_f1:.4f} < {PERFORMANCE_THRESHOLDS["min_macro_f1"]:.2f}',
                'actions': [
                    'Ajustar learning rate en train.py:',
                    '  - Si converge r√°pido pero bajo rendimiento: aumentar a 2e-4 o 5e-4',
                    '  - Si oscila mucho: reducir a 5e-5',
                    'Probar learning rate scheduler diferente:',
                    '  - CosineAnnealingLR para convergencia suave',
                    '  - OneCycleLR para training m√°s r√°pido',
                    'Ajustar ReduceLROnPlateau: patience=5 ‚Üí 7, factor=0.5 ‚Üí 0.3'
                ]
            }
            recommendations.append(rec)
            priority_actions.append("üìä Ajustar Learning Rate")
        
        # 4. Problemas de Epochs
        if accuracy < PERFORMANCE_THRESHOLDS['target_overall_accuracy']:
            rec = {
                'category': 'Training Duration',
                'priority': 'MEDIUM',
                'issue': f'Accuracy no alcanza objetivo: {accuracy:.4f} < {PERFORMANCE_THRESHOLDS["target_overall_accuracy"]:.2f}',
                'actions': [
                    'Aumentar n√∫mero de epochs en train.py:',
                    '  - EPOCHS_PHASE1: 100 ‚Üí 150',
                    'Ajustar early stopping patience:',
                    '  - patience: 15 ‚Üí 20',
                    'Considerar entrenamiento en m√∫ltiples fases:',
                    '  - Fase 1: Congelar base, entrenar top layers',
                    '  - Fase 2: Fine-tuning gradual de capas base'
                ]
            }
            recommendations.append(rec)
            priority_actions.append("‚è±Ô∏è  Aumentar Epochs")
        
        # 5. Problemas de confusi√≥n entre clases similares
        if len(confusions) > 10:
            rec = {
                'category': 'Architecture',
                'priority': 'MEDIUM',
                'issue': f'{len(confusions)} confusiones significativas detectadas',
                'actions': [
                    'Considerar arquitectura m√°s compleja:',
                    '  - EfficientNetB1 o B2 (m√°s capacidad que MobileNetV2)',
                    '  - ResNet50 o ResNet101 para features m√°s discriminativas',
                    'Aumentar tama√±o de imagen:',
                    '  - IMG_SIZE: 224 ‚Üí 299 (cuidado con memoria)',
                    'Agregar capas de attention para enfoque en s√≠ntomas:',
                    '  - Attention mechanism despu√©s de base model',
                    '  - Spatial attention para regiones importantes'
                ]
            }
            recommendations.append(rec)
            priority_actions.append("üèóÔ∏è  Cambiar Arquitectura")
        
        # 6. Problemas espec√≠ficos de clases cr√≠ticas
        critical_issues = [c for c in problematic_classes if c['is_critical_disease']]
        if critical_issues:
            rec = {
                'category': 'Critical Diseases',
                'priority': 'CRITICAL',
                'issue': f'{len(critical_issues)} enfermedades cr√≠ticas con bajo rendimiento',
                'actions': [
                    'PRIORIDAD M√ÅXIMA - Enfermedades cr√≠ticas:',
                    '  - ' + ', '.join([c['class_name'] for c in critical_issues]),
                    'Acciones espec√≠ficas:',
                    '  - Aumentar weight de estas clases en class_weights',
                    '  - Aplicar augmentation m√°s intenso',
                    '  - Recolectar m√°s datos si es posible',
                    '  - Usar focal loss (USE_FOCAL_LOSS=True en config.py)',
                    '  - Aumentar FOCAL_LOSS_GAMMA para enfoque en casos dif√≠ciles'
                ]
            }
            recommendations.insert(0, rec)  # Primera prioridad
            priority_actions.insert(0, "üî¥ CR√çTICO: Mejorar enfermedades cr√≠ticas")
        
        # 7. Confusi√≥n inter-cultivo
        if error_patterns['inter_crop_confusion']:
            rec = {
                'category': 'Data Quality',
                'priority': 'HIGH',
                'issue': 'Confusi√≥n entre diferentes tipos de cultivos',
                'actions': [
                    'Revisar calidad de im√°genes:',
                    '  - Verificar que im√°genes est√©n correctamente etiquetadas',
                    '  - Eliminar im√°genes ambiguas o de baja calidad',
                    'Mejorar preprocessing:',
                    '  - Aplicar crop autom√°tico para enfocarse en hojas',
                    '  - Normalizaci√≥n por cultivo si hay diferencias de iluminaci√≥n',
                    'Augmentation espec√≠fico por cultivo:',
                    '  - Ajustar par√°metros seg√∫n caracter√≠sticas de cada planta'
                ]
            }
            recommendations.append(rec)
            priority_actions.append("üîç Revisar calidad de datos")
        
        # 8. Confusi√≥n healthy vs diseased
        if error_patterns['healthy_vs_diseased_errors']:
            rec = {
                'category': 'Feature Learning',
                'priority': 'HIGH',
                'issue': 'Confusi√≥n entre plantas sanas y enfermas',
                'actions': [
                    'Mejorar capacidad de detectar s√≠ntomas sutiles:',
                    '  - Aumentar tama√±o de imagen para capturar detalles',
                    '  - Usar arquitectura con mejor resoluci√≥n espacial',
                    'Ajustar class weights:',
                    '  - Aumentar peso de clases "healthy" si tienen bajo recall',
                    '  - O aumentar peso de clases enfermas si tienen bajo recall',
                    'Preprocessing espec√≠fico:',
                    '  - Realce de contraste para destacar s√≠ntomas',
                    '  - Color augmentation cuidadoso (no cambiar colores de s√≠ntomas)'
                ]
            }
            recommendations.append(rec)
            priority_actions.append("üåø Mejorar detecci√≥n healthy vs diseased")
        
        # Mostrar recomendaciones
        for i, rec in enumerate(recommendations, 1):
            if rec['priority'] == 'CRITICAL':
                priority_icon = f"{RED}üî¥ CR√çTICO{RESET}"
            elif rec['priority'] == 'HIGH':
                priority_icon = f"{YELLOW}‚ö†Ô∏è  ALTO{RESET}"
            else:
                priority_icon = f"{BLUE}‚ÑπÔ∏è  MEDIO{RESET}"
            
            print(f"{BOLD}{i}. {rec['category']}{RESET} - {priority_icon}")
            print(f"   {CYAN}Problema:{RESET} {rec['issue']}")
            print(f"   {GREEN}Acciones:{RESET}")
            for action in rec['actions']:
                print(f"   {action}")
            print()
        
        self.analysis['recommendations'] = recommendations
        self.analysis['priority_actions'] = priority_actions
        
        return recommendations
    
    def generate_summary(self):
        """Genera resumen del an√°lisis."""
        print(f"{BOLD}{'='*70}{RESET}")
        print(f"{BOLD}üìã RESUMEN DEL AN√ÅLISIS{RESET}")
        print(f"{BOLD}{'='*70}{RESET}\n")
        
        # Estad√≠sticas
        n_problematic = len(self.analysis['problematic_classes'])
        n_critical = len([c for c in self.analysis['problematic_classes'] 
                         if c['severity'] == 'CRITICAL'])
        n_confusions = len(self.analysis['confusion_patterns'])
        n_recommendations = len(self.analysis['recommendations'])
        
        print(f"{BOLD}Clases Problem√°ticas:{RESET} {n_problematic}")
        if n_critical > 0:
            print(f"  {RED}‚Ä¢ Cr√≠ticas: {n_critical}{RESET}")
        if n_problematic - n_critical > 0:
            print(f"  {YELLOW}‚Ä¢ Advertencias: {n_problematic - n_critical}{RESET}")
        
        print(f"\n{BOLD}Patrones de Confusi√≥n:{RESET} {n_confusions}")
        print(f"{BOLD}Recomendaciones:{RESET} {n_recommendations}")
        
        # Acciones prioritarias
        if self.analysis['priority_actions']:
            print(f"\n{BOLD}üéØ ACCIONES PRIORITARIAS:{RESET}")
            for i, action in enumerate(self.analysis['priority_actions'], 1):
                print(f"{i}. {action}")
    
    def save_report(self, output_path: str = None):
        """
        Guarda el reporte de an√°lisis en JSON.
        
        Args:
            output_path: Ruta donde guardar el reporte
        """
        if output_path is None:
            output_path = backend_dir.parent / 'metrics' / 'failure_analysis.json'
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.analysis, f, indent=2, ensure_ascii=False)
        
        print(f"\n{GREEN}‚úÖ Reporte de an√°lisis guardado en: {output_path}{RESET}")
    
    def run_analysis(self) -> Dict[str, Any]:
        """
        Ejecuta el an√°lisis completo.
        
        Returns:
            Diccionario con an√°lisis completo
        """
        print(f"\n{BOLD}{'='*70}{RESET}")
        print(f"{BOLD}üîç AN√ÅLISIS DE PROBLEMAS DEL MODELO - PASO 5{RESET}")
        print(f"{BOLD}{'='*70}{RESET}")
        
        # Cargar datos
        if not self.load_data():
            return None
        
        # 1. Identificar clases problem√°ticas
        problematic_classes = self.identify_problematic_classes()
        
        # 2. Analizar confusion matrix
        confusions = self.analyze_confusion_matrix()
        
        # 3. Detectar patrones de error
        error_patterns = self.detect_error_patterns()
        
        # 4. Generar recomendaciones
        recommendations = self.generate_recommendations(
            problematic_classes, confusions, error_patterns
        )
        
        # 5. Generar resumen
        self.generate_summary()
        
        # 6. Guardar reporte
        self.save_report()
        
        return self.analysis


def main():
    """Funci√≥n principal."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='An√°lisis de problemas del modelo (Paso 5)'
    )
    parser.add_argument(
        '--results',
        type=str,
        default=None,
        help='Ruta al archivo JSON con resultados de evaluaci√≥n'
    )
    parser.add_argument(
        '--validation',
        type=str,
        default=None,
        help='Ruta al archivo JSON con reporte de validaci√≥n'
    )
    parser.add_argument(
        '--output',
        type=str,
        default=None,
        help='Ruta donde guardar el reporte de an√°lisis'
    )
    
    args = parser.parse_args()
    
    # Ejecutar an√°lisis
    analyzer = FailureAnalyzer(args.results, args.validation)
    result = analyzer.run_analysis()
    
    if result is not None:
        if args.output:
            analyzer.save_report(args.output)
    
    sys.exit(0 if result is not None else 1)


if __name__ == '__main__':
    main()
